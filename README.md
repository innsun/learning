# learning

<table style="border-collapse:collapse;font-size:12px">
  <tr style="background-color:#eee">
    <th style="border:none;width:130">学习阶段</th>
    <th style="border:none;width:30">日期</th>
    <th style="border:none">描述</th>
    <th style="border:none;width:180">课程材料</th>
  </tr>
  <tr>
    <td style="border:none">环境配置</td>
    <td style="border:none"></td>
    <td style="border:none">配置好python开发环境，熟悉pyCharm的使用</td>
    <td style="border:none">
      <a href="https://www.continuum.io/downloads">基础环境python2.7下载</a><br/>
      <a href="https://www.jetbrains.com/pycharm/download/#section=windows">开发环境pycharm5.04下载</a><br/>
      <a href="http://www.zhihu.com/question/27615938">winpython,anaconda哪个更好？</a><br/>
      <a href="/python/python环境配置_20160316.doc">参考文件路径</a>
    </td>
  </tr>
  <tr>
    <td style="border:none">学习资料准备</td>
    <td style="border:none"></td>
    <td style="border:none"></td>
    <td style="border:none">
      <a href="https://www.coursera.org/learn/machine-learning">视频教程</a><br/>
      <a href="http://product.dangdang.com/23760742.html">概率论与数理统计</a><br/>
      <a href="http://product.dangdang.com/20942891.html">线性代数</a>
    </td>
  </tr>
  <tr>
    <td style="border:none">机器学习视频教程</td>
    <td style="border:none"></td>
    <td style="border:none">总共19节课，每周6节，三周完成全部课程</td>
    <td style="border:none">
      <a href="https://www.coursera.org/learn/machine-learning">视频教程</a><br/>
      <a href="http://baike.baidu.com/link?url=cbQBFt77LMfMNq1jDVEMBe-DOiLPMbXHi5J1PyMrdNA_cIqqZXFbiwqLq4ZZGGbvmz8Ffg7tTFivQBhv8pTL1a">讲课老师：吴恩达</a><br/>
    </td>
  </tr>
  <tr>
    <td style="border:none">贝叶斯文本分类器</td>
    <td style="border:none"></td>
    <td style="border:none">
      学习<a href="http://product.dangdang.com/23760742.html">概率论与数理统计</a>第一、二章知识<br/>
      用第一章知识点（包括，不限于：基本事件，样本空间，独立事件，贝叶斯公式等）解释贝叶斯文本分类器
    </td>
    <td style="border:none"></td>
  </tr>
  <tr>
    <td style="border:none">逻辑回归</td>
    <td style="border:none"></td>
    <td style="border:none">
      学习<a href="http://product.dangdang.com/20942891.html">线性代数</a>第一、二章知识
      使用矩阵运算实现逻辑回归的向量化版本
    </td>
    <td style="border:none">
      <a href="data_set/comment_sentiment">数据集</a><br/>
    </td>
  </tr>
  <tr>
    <td style="border:none">朴素贝叶斯文本分类器</td>
    <td style="border:none"></td>
    <td style="border:none">
      使用矩阵运算实现朴素贝叶斯文本分类器的向量化版本
    </td>
    <td style="border:none">
      <a href="data_set/comment_sentiment">数据集</a><br/>
    </td>
  </tr>
  <tr>
    <td style="border:none">高斯判别模型理解文档</td>
    <td style="border:none"></td>
    <td style="border:none">
      学习<a href="http://product.dangdang.com/23760742.html">概率论与数理统计</a>第三、四章知识
      用第四章知识点（包括，不限于：协方差矩阵，n维正态随机变量的概率密度等）来解释高斯判别模型
    </td>
    <td style="border:none"></td>
  </tr>
  <tr>
    <td style="border:none">高斯判别模型代码</td>
    <td style="border:none"></td>
    <td style="border:none">
      实现高斯判别模型文本分类算法
    </td>
    <td style="border:none">
      <a href="data_set/comment_sentiment">数据集</a><br/>
    </td>
  </tr>
  <tr>
    <td style="border:none">神经网络</td>
    <td style="border:none"></td>
    <td style="border:none">
      使用神经网络实现手写数字识别
    </td>
    <td style="border:none">
      <a href="data_set/mnist">数据集</a><br/>
      <a href="http://yann.lecun.com/exdb/mnist/">数据集网址</a><br/>
    </td>
  </tr>
  <tr>
    <td style="border:none">softmax回归</td>
    <td style="border:none"></td>
    <td style="border:none">
      学习概率论与数理统计第七章分布函数的参数估计方法<br/>
      学习softmax归回，理解softmax回归的应用背景，推导softmax的代价函数，并分别对x和theta求导
    </td>
    <td style="border:none"></td>
  </tr>
  <tr>
    <td style="border:none">softmax神经网络</td>
    <td style="border:none"></td>
    <td style="border:none">
      完善神经网路手写数字识别<br/>
      神经网络输出层使用softmax回归实现
    </td>
    <td style="border:none"></td>
  </tr>
  <tr>
    <td style="border:none">softmax和两层神经网络</td>
    <td style="border:none"></td>
    <td style="border:none">
      实现<a href="project/ltDLA1/cs231n/classifiers">classifiers</a>文件夹下softmax.py，neural_net.py的todo部分的代码
    </td>
    <td style="border:none">
      <a href="project/ltDLA1">工程</a><br/>
      <a href="data_set/cifar-10-batches-py">数据集</a>
    </td>
  </tr>
  <tr>
    <td style="border:none">斯坦福大学cs229课程</td>
    <td style="border:none"></td>
    <td style="border:none"></td>
    <td style="border:none">
      <a href="http://open.163.com/special/opencourse/machinelearning.html">课程网址</a><br/>
      <a href="http://baike.baidu.com/link?url=cbQBFt77LMfMNq1jDVEMBe-DOiLPMbXHi5J1PyMrdNA_cIqqZXFbiwqLq4ZZGGbvmz8Ffg7tTFivQBhv8pTL1a">讲课老师：吴恩达</a><br/>
    </td>
  </tr>
  <tr>
    <td style="border:none">斯坦福大学cs231n课程</td>
    <td style="border:none"></td>
    <td style="border:none"></td>
    <td style="border:none">
      <a href="http://cs231n.stanford.edu/">课程网址</a><br/>
      <a href="http://baike.baidu.com/link?url=j6j_IoaVUNRPWnKwKXXYeibTugDOQ_WTMjZX-FRp9qvxB-qd1KGeHF5-hCzjpeIs0CxPrkYj0rVA6vMnEa2xuK">讲课老师：李飞飞</a><br/>
    </td>
  </tr>
  <tr>
    <td style="border:none">KNN和SVN作业</td>
    <td style="border:none"></td>
    <td style="border:none">
      实现<a href="project/ltDLA1">工程</a>中knn.py，svm.py的todo部分的代码
      实现<a href="project/ltDLA1/cs231n/classifiers">classifiers</a>文件夹下linear_svm.py，k_nearest_neighbor.py的todo部分的代码
    </td>
    <td style="border:none">
      <a href="data_set/cifar-10-batches-py">数据集</a><br/>
    </td>
  </tr>
</table>
